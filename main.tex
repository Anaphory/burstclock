%% Author_tex.tex
%% V1.0
%% 2012/13/12
%% developed by Techset
%% 
%% This file describes the coding for rsproca.cls

\documentclass[]{rsos}%%%%where rsos is the template name

%%%% *** Do not adjust lengths that control margins, column widths, etc. ***

% General style
\usepackage{newunicodechar}
\newunicodechar{→}{\fontspec{Gentium Plus}→}
\newunicodechar{–}{--}
\newunicodechar{“}{``}
\newunicodechar{”}{''}
\newunicodechar{‘}{`}
\newunicodechar{’}{'}

% Formulas
\usepackage{amsmath}
\usepackage{amssymb}

% Internal references
\usepackage[titletoc,title]{appendix}
\usepackage{hyperref}
\usepackage[capitalize]{cleveref}
\Crefname{appsec}{Appendix}{Appendices}
\crefname{appsec}{appendix}{appendices}

% Figures
\usepackage{subcaption}
\usepackage[font=small,labelfont=it]{caption}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{bayesnet}
\usepackage[linguistics,edges]{forest}
\usepackage{rotating}

% Bibliography
\usepackage[backend=biber,
            bibstyle=numeric-comp, %biblatex-sp-unified,
            citestyle=numeric-comp,
            sorting=none,
            maxcitenames=2,url=false,
            maxbibnames=10]{biblatex}
\addbibresource{library.bib}
\def\bibfont{\fontfamily{\rmdefault}\fontseries{m}\fontshape{n}\fontsize{9}{11}\selectfont}

\renewbibmacro*{doi+eprint+url}{%
  \printfield{doi}%
  \newunit\newblock%
  \iftoggle{bbx:eprint}{%
    \usebibmacro{eprint}%
  }{}%
  \newunit\newblock%
  \iffieldundef{doi}{%
    \usebibmacro{url+urldate}}%
  {}%
}

\newcommand{\glot}[2]{#1 {\scriptsize{[\texttt{\href{https://glottolog.org/resource/languoid/id/#2}{#2}}]}}}

% Code inclusion with syntax highlighting
\usepackage{minted}
\setminted{fontsize=\tiny,baselinestretch=0.9}

\begin{document}

\title{Clocks with bursts: Phylogenetic inference of schismogenesis in language evolution}
\date{\today}
\Year{2022}
\author{
  Gereon A. Kaiping$^{1}$,
  Nico Neureiter$^{1}$}
\address{$^{1}$Geographic Information Science Center, Universität Zürich, CH}
\subject{Linguistics, Bioinformatics}
\keywords{Language Evolution, Phylogenetics, Schismogenesis}

\corres{Gereon A. Kaiping\\
  \email{gereon.kaiping@geo.uzh.ch}}

% Aim: 200 words or less
\begin{abstract}
Dated language phylogenies, with broad uses in historical and anthropological
research, depend on good models of linguistic evolution.
When a language splits into different speaker communities, the speed of
language change increases such that a
significant proportion of lexical disparity can be attributed
to the splitting events, potentially arising from linguistic founder effects or from
“schis\-mo\-gen\-e\-sis”, i.\,e.
the exaggeration of language differences to mark social boundaries.
Surprisingly, this result has not found its way back
into the clock models used in phylogenetic inference. Here, we develop an
extension to existing phylogenetic clock models in BEAST2 to
account for bursts at language splits. We use simulation studies and also fit
the new model to four major language families of the world: Austronesian,
Bantu, Indo-European, and Sino-Tibetan. We find that the burst clock fits the
data better than either a Strict Clock or an Uncorrelated Relaxed Clock, and that
a binary split is associated with $10^{-4}$ to $10^{-3}$ lexical changes per item of basic
vocabulary. This is equivalent to the amount of lexical change a language
accumulates in about 100 years of independent evolution without splits.
This makes bursts at splits a major contribution to language evolution,
and our model may even be applicable to some cases of biological evolution.
\end{abstract}


\begin{fmtext}
\section{Introduction}
Phylogenetic inference methods reconstruct the e\-volu\-tion\-ary tree of a group of
relatives, i.\,e. their hierarchy of common ancestors.
These methods were originally developed for biological organisms, but have seen extensive
use in the study of cultural evolution \parencite{evans2021uses}, in particular in
linguistics.
\end{fmtext}
\maketitle
With the advent of computer-coded wordlist data sets, the big driver of
phylogenetic methods in linguistics has been their ability to date language
histories based on a relatively small number of broad calibration points
\parencite{borchsenius2017phylogenetics}.
Modern phylogenetic inference methods assume that evolution is driven by
stochastic processes. Using stochastic sampling methods and computational models,
an inference program such as BEAST2 \parencite{drummond2015bayesian}
generates a sample of trees and parameter values that fit the data and the prior knowledge
about the evolutionary process.

The quality of the inference output depends on the quality of the prior
distributions and of the model describing the evolutionary process. Because the
methods were originally developed for biological applications, many models and
priors used in cultural phylogenetics are biologically motivated, and have been
empirically compared on linguistic data afterwards, if at all
\parencite{kaiping2021systematic,rama2018three}.

There is however qualitative and quantitative research in comparative
linguistics which could motivate models based on the evolutionary processes in
languages. For example, linguistic differences, in particular those apparent to
speakers, are often exaggerated among different social groups to mark social
boundaries. This process, dubbed schismogenesis by \textcite{bateson1935culture}
and esoterogeny by \textcite{thurston1987processes}, is thought to be a major
driver of language diversity in as wide a range of locations as Vanuatu
\parencite{francois2011social}, Australia and New Guinea
\parencite{evans2019linguistic}, and South America
\parencite{epps2020amazonian}. It is likely also a factor in other parts of the
world.

Languages function to identify in-groups, and as such they mark social
boundaries \parencite{labov1963social,epps2020amazonian}.
% In some known cases, they thus serve to define potential marriage partners in exogamous societies, such that language differences are maintained even where peoples strongly mix \parencites[p. 17f]{aikhenvald2002language}, but linguistic exogamy is not the only factor that leads to language differences being maintained \parencite{epps2020amazonian}.
While contact-induced divergence \parencite{evans2019linguistic} can continue
throughout the evistence of a language, these linguistic processes presumably
matter most at times when languages split, driving the schism (thus
“schismogenesis”) and in turn being driven by the observation of exaggerated
differences. A lineage with more language diversification would thus be more
different from a common ancestral language than its individual sibling language
which has not undergone any splits, despite the fact that the same amount of
time has passed from the ancestral language to the modern languages in each
case.

Quantitative evidence for this effect was supplied by
\textcite{atkinson2008languages}. Using lexical cognate data, they studied the
signal of punctuated equilibrium \parencite{eldredge1972punctuated} in the
Austronesian, Bantu, and Indo-European tree.
Lexical data is the standard data type in linguistic phylogenies,
but significant in the contex of schismogenesis:
The lexicon is one of the domains
of language most apparent to speakers and accessible to conscious manipulation
\parencite[see][for an extensive discussion]{thomason2007language}, and thus a
likely target of schismogenesis – along with a language's phonology, which is
however a domain with much less established quantitative and phylogenetic
methodology. \Citeauthor{atkinson2008languages} found that between 9.5\% and
33\% of lexical differences are due to punctuated events.

% Rama & Wichmann (2020) infer $t = 1843 × MTL^0.35$, regressing the *median
% length* (not height) of the tree sample to the otherwise estimated age of the
% language family. This might have an interpretation in our context? I don't
% know what, though.

\Textcite{gray2013three} raise the question whether this would be different for
other linguistic domains. They argue that “[t]o the extent that closely related
speech communities differ more in accent than they do in vocabulary, and more in
vocabulary than in language structure, it might be predicted that the
schismogenesis effect would be most pronounced in phonetics and least in
structural features of language.” \parencite[p. 295]{gray2013three} However,
there are other potential explanations for the phenomenon of increased
linguistic disparity in lineages with more splits. There might instead be
founder effects \parencite{atkinson2008languages,greenhill2017evolutionary},
or correlations between split rates and evolutionary divergence.

In order to test this, first an explicit model of punctuated evolution
is necessary. In addition to contributing to our understanding of
schismogenesis in cross-cultural interaction, such a model will also benefit
the field of language phylogeny in general. Phylogenic studies will benefit
greatly from explicit modelling of the punctuated evolution, for a better
estimation of branch rates and thus time depths.

We present such an explicit “burst clock” model in this article, and test it
both on simulation data, in order to see whether phylogenetic inference is able
to distinguish between data generated with and without bursts at language
splits, as well as on four well-studied language families.

\paragraph{The structure of the paper} is as follows. In \cref{s:description},
we describe the burst clock model, a generalization of existing phylogenetic
clock models. We provide and describe a BEAST2 \parencite{drummond2015bayesian}
package implementing this clock. In \cref{s:simulation}, we show using a
simulation study that the burst clock model can distinguish between data
generated with evolutionary bursts at the languages' splits and those without,
and that a clock model without bursts mis-estimates tree parameters when applied
to data generated with bursts. We then present four case studies with empirical
data, each using the same Bayesian phylogenetic inference method with clocks
with optional bursts, in \cref{s:lexical}. We present one study each with
lexical data of Austronesian \ref{s:austronesian}, Bantu \ref{s:bantu},
Indo-European \ref{s:indoeuropean}, and Sino-Tibetan \ref{s:sinotibetan}. We
present our results in \cref{s:results}, first for the simulation study, then
for each case study. In \cref{s:discussion}, we discuss the results and
formulate our conclusions.

Data and methods used to produce the results and figures shown in this paper are
available as online Supplementary Material and through
\url{https://osf.io/??????????????????}.

\section{Introducing the burst clock model}\label{s:description}
\begin{figure}
    \centering
      \begin{tikzpicture}
        \tikzset{vertex/.style = {shape=rectangle,draw,minimum size=1.5em,align=center,text height=1.5ex,text depth=.25ex}}
        \tikzset{edge/.style = {-{to[length=3mm]}}}
        \node[vertex] (root) at  (0.5,4) {$r$};
        \node[vertex] (i) at  (3,0) {$i$};
        \node[vertex,draw=none] (x) at  (1,0) {};
        \node[vertex,dotted] (u) at  (2,2) {};
        \node[vertex] (l1) at  (-2,1) {};
        \node[vertex] (l2) at  (-1,0) {};
        \node[vertex] (l3) at  (-3,0) {};
        \node[vertex] (l4) at  (-1,3) {};
        \node[vertex] (l5) at  (0,0) {};
        \draw[draw=none] (root) -|
        node[midway,name=r,minimum size=1.5em] {}
        (i);
        \draw[edge] (root) -|
        node[pos=0.1] {$\bullet$}
        node[pos=0.2] {$\bullet$}
        node[pos=0.3] {$\bullet$}
        node[pos=0.4] {$\bullet$}
        (u);
        \draw[edge] (u) -|
        node[pos=0.1] {$\bullet$}
        node[pos=0.2] {$\bullet$}
        node[pos=0.3] {$\bullet$}
        node[pos=0.4] {$\bullet$}
        (i);
        \draw[edge,gray!40] (u) -|
        node[pos=0.1,text=gray!40] {$\bullet$}
        node[pos=0.2,text=gray!40] {$\bullet$}
        node[pos=0.3,text=gray!40] {$\bullet$}
        node[pos=0.4,text=gray!40] {$\bullet$}
        (x);
        \draw[edge] (root) -|
        node[pos=0.1] {$\bullet$}
        node[pos=0.2] {$\bullet$}
        node[pos=0.3] {$\bullet$}
        node[pos=0.4] {$\bullet$}
        (l4);
        \draw[edge] (l4) -|
        node[pos=0.1] {$\bullet$}
        node[pos=0.2] {$\bullet$}
        node[pos=0.3] {$\bullet$}
        node[pos=0.4] {$\bullet$}
        (l1);
        \draw[edge] (l1) -|
        node[pos=0.1] {$\bullet$}
        node[pos=0.2] {$\bullet$}
        node[pos=0.3] {$\bullet$}
        node[pos=0.4] {$\bullet$}
        (l2);
        \draw[edge] (l1) -|
        node[pos=0.1] {$\bullet$}
        node[pos=0.2] {$\bullet$}
        node[pos=0.3] {$\bullet$}
        node[pos=0.4] {$\bullet$}
        (l3);
        \draw[edge] (l4) -|
        node[pos=0.1] {$\bullet$}
        node[pos=0.2] {$\bullet$}
        node[pos=0.3] {$\bullet$}
        node[pos=0.4] {$\bullet$}
        (l5);
        \draw[decorate,decoration={brace,mirror,raise=1ex}]
        (i.east) -- node [midway,right=3ex] {$l_i$} (r.east);

        \node at  (-3,0.5) {$\bullet$};
        \node at  (-1,0.5) {$\bullet$};
        \node at  (-2,1.5) {$\bullet$};
        \node at  (-2,2.5) {$\bullet$};
        \node at  (0,0.5) {$\bullet$};
        \node at  (0,1.5) {$\bullet$};
        \node at  (0,2.5) {$\bullet$};
        \node at  (-1,3.5) {$\bullet$};
        \node[text=gray!40] at  (1,0.5) {$\bullet$};
        \node[text=gray!40] at  (1,1.5) {$\bullet$};
        \node at  (3,0.5) {$\bullet$};
        \node at  (3,1.5) {$\bullet$};
        \node at  (2,2.5) {$\bullet$};
        \node at  (2,3.5) {$\bullet$};
    
     \node at (3, -0.5) {$e_i = c \cdot l_i + b (1 + u_i)$};
    \end{tikzpicture}
    \caption{The burst clock model: For $b>0$, the amount of change $e_i$ (symbolized
      by $\bullet$s) that is
      accumulated from a parent $r$ to its descendant $i$ depends on the number of
      ancestral nodes (observed and unobserved) between $r$ and $i$}
    \label{f:burstclock}
\end{figure}
A linguistic phylogenetic inference attempts to re-construct the evolutionary
tree of a language family from linguistic data. The predominant approach uses
lexical data to infer binary trees (where each internal node represents a split
of a single ancestral language into two daughter languages). The compatibility to the data
of a particular model (a tree together with an evolutionary process, including
all the parameters of the process) is given by the posterior probability of the
model given the data, which according to Bayes' theorem can be computed from
likelihood of the data under the model and the prior probability of the model.
\begin{align}
    P(\text{Model}\mid\text{Data}) \propto P(\text{Data}\mid\text{Model}) \cdot P(\text{Model})
\end{align}
Using Markov chain Monte Carlo sampling (MCMC), the inference software generates
a sample from this posterior distribution.

Such a Bayesian inference needs to describe the evolutionary process in terms of
the overall assumed shape of evolutionary trees (the tree prior), the process
that drives the evolutionary divergence by changing the data along a branch (the
substitution model), and the mapping between the length of a branch in the
phylogeny to the amount of change along that branch (the branch rate model).

In linguistic phylogenies, analyses that are concerned only with linguistic
subgrouping may use tree priors and branch rate models that produce
non-ultrametric trees, which do not permit ascribing times to nodes and
branches. Otherwise, they tend to use one of two ‘clock models’. Clock models
assume that each split happens at a particular point in time, so each branch
represents a time span. The clock model then describes the relationship between time and
evolutionary divergence.

In a strict clock,
the expected number of changes $e_i$ on the branch leading to node $i$ is the product of a constant clock rate $c$ and the temporal length $l_i$ (usually measured in years)
\begin{align}
  e_i = c \cdot l_i
  \label{eq:strict}
\end{align}
This mapping between time and expected number of evolutionary changes goes back
to the “molecular clock” observation in the 1960s
\parencite{zuckerkandl1965evolutionary,kumar2005molecular}. Since then, a variety of clock models
has been developed and applied in biology (see \parencite{ho2014molecularclock} for an
overview).
% https://onlinelibrary.wiley.com/doi/full/10.1111/mec.12953: This was
% transformed by the development of the molecular clock in the 1960s
% (Zuckerkandl & Pauling 1962, 1965; Margoliash 1963; Doolittle & Blombäck 1964)

The other frequently used branch rate model in linguistics is the uncorrelated relaxed
clock (URC), which is a generalization of the strict clock.
The URC \parencite{drummond2006relaxed} permits the clock rate $c$ to depend on
the branch, instead of being constant throughout the tree. Clock
rates $c_i$ for each branch are drawn from independent, identically distributed random
variables, so the branch rates are a priori uncorrelated.
The URC was introduced to linguistic
phylogenetics by \textcite{kitchen2009bayesian}, and has generally been seen to
fit the data better than a strict clock
\parencite{bouckaert2012mapping,honkola2013cultural,lee2013evolution}
(Exceptions: \cite{savelyev2020bayesian,kaiping2021systematic})
and has found its way into current general advice on linguistic phylogenies
\parencite{maurits2017beastling,hoffmann2021bayesian}.

The burst clock, which we introduce here, generalizes the strict clock in a different manner, which can be combined with relaxed clock models.
The strict clock and the URC both assume that all change is accumulated gradually
through time.
For the burst clock, we instead assume that bursts of evolution at split events
contribute to the diversification of languages.
At every split, the burst clock contributes a
constant amount of expected change to the evolutionary history of the
descendant languages, see \cref{f:burstclock}. That is, in addition to the clock rate parameter $c$, this clock model
has a burst parameter, another non-negative scalar value $b$.
The expected number of changes is
\begin{align}
  e_i = c \cdot l_i + b
  \label{eq:simple-burst}
\end{align}
For $b=0$, this model reduces to the strict clock without bursts.

% NOTE: Don't do, and don't discuss, relaxed-burst relaxed clocks.
%
% Like the strict clock can be relaxed, eg. by drawing per-branch clock rates
% $c_i$ from a lognormal distribution \parencite{}, so can the parameter $b$ be
% extended to per-node burst values $b_i$. For $c=0$, this gives rise to
% non-clock models, and with an appropriate model of the $b_i$ can represent
% various non-clock priors, such as the compound Dirichlet prior (Rannala et al.
% 2012). https://academic.oup.com/sysbio/article/61/5/779/1735441
% The focus of this article, however, is on the simple extension of clock models where $b$ is constant.

If all languages of a family under study were attested, and thus all splits throughout
the family's history were to show up in the evolutionary tree, this model would be sufficient.
However, in no language family do we expect to know all languages, and in most
language families even the contemporary languages are not completely known \parencite{glottoscope}. 
Unobserved splits, where a language splits in two, but one of
the two descendant branches goes extinct before being observed or is not sampled,
should contribute to language change in the same manner as observed splits.
For $u_i$ unobserved changes on the branch leading to $i$, we would thus expect $e_i = c \cdot l_i + b + u_i \cdot b$ changes.

We therefore need to find an estimate for the unobserved splits.
We do this here for a specific tree prior.
One of the most frequently used tree priors in linguistic phylogenies
is the (fossilized) birth-death tree prior \parencite{gernhard2008conditioned,stadler2010samplingthroughtime,heath2014fossilized,rama2018three}.
Under this prior, the rate at which
languages split (birth rate $\lambda$) is either included explicitly or in terms of net diversification rate and turnover.
The expected number of splits along a branch is then $\lambda \cdot l_i$, and one of these –~the one where the branch begins~– is observed, so $1 + u_i = \lambda \cdot l_i$.

For a sampling proportion $q$ and $t$ observed leaves, the total number of unobserved and observed leaves will be
$\frac{t}{q}$, so there are $\frac{t}{q} - 1$ net splits,
while the observed number of splits will be $t - 1$. This means that the proportion of unobserved splits is, on average,
\begin{align}
  \frac{u_i}{l_i \lambda}
  &= \frac{u_i}{E[u_i + 1]} \\
  % This approximation could probably do with a better argument
  & \approx \frac{(\frac{t}{q} - 1) - (t - 1)}{\frac{t}{q} -1} \\
  & = \frac{t - q - qt + q}{t - q} \\
  & = \frac{t - qt}{t - q} \\
  & \approx \frac{t - qt}{t} &\text{because } q \leq 1 \ll t \\
  & = 1 - q
\end{align}
giving rise to the expected number of changes
\begin{align}
  e_i &= c \cdot l_i + b + u_i \cdot b  \\
  &= c \cdot l_i + b + \lambda l_i b \\
  &= (c + \lambda (1-q) b) \cdot l_i + b
  \label{eq:reparam-burst}
  % Just using $u_i = \lambda l_i - 1$ gives instead
  % e_i &= c \cdot l_i + b + (\lambda l_i - 1) \cdot b  \\
  % &= (c + \lambda b) \cdot l_i \\
  % and thus a clock without bursts. This is not what we want. But a
  % mathematically inclined reader might wonder.
\end{align}
This is formally the same model as in \cref{eq:simple-burst}: The expected amount of change is linear (with a non-zero intercept) in the branch length. It is, however, parameterized
in a way that takes the underlying tree prior into account,
which should lead to better mixing and better interpretability.

This model extends to non-strict clocks in a straightforward manner, where with per-branch clock rates $c_i$, we get
\begin{align}
  e_i = (c_i + \lambda (1-q) b) \cdot l_i + b
  \label{eq:relaxed}
\end{align}
to obtain a relaxed burst clock.
The strict burst clock and the relaxed burst clock can both be generated using one common implementation, which wraps any internal clock model exposing branch lengths and clock rates.
We implemented such a burst clock wrapper as a BEAST2 package (\texttt{burstclock}).
The implementation is available from XXX.

\section{Simulation Study}
\label{s:simulation}
For the computational model to be useful, it needs to behave differently from
other models. With a simulation study, we aim to show that the burst clock model is able to
infer that a simulated evolutionary process contained bursts, and how big those bursts were.
This is in particular relevant for the relaxed clock model with bursts.
% Why we need a simulation study
Because the relaxed burst clock allows two ways of modifying the expected number
of changes per branch to match the data, it is not clear a priori that a burst
clock and a relaxed clock can be distinguished.
Inference with the burst clock model must be able to identify simulated bursts, and distinguish them from the relaxed clock rates, even when clock rates differ significantly across branches. The strict clock is a special case of the relaxed clock, so if we can show that the relaxed clock is identifiable, that is sufficient to imply identifiability also for the strict clock.

In order to investigate this,
we follow the procedure described by \textcite{cook2006validation} and perform a simulation study in four steps: (1) Sample ground truth parameters according to a prior distribution. (2) Simulate data according to the prior predictive distribution of the burst clock model. (3) Sample parameters from the posterior based on the simulated data, using a burst clock and for comparison a clock without bursts. (4) Evaluate the quantile of the ground truth parameters in the posterior sample.
We repeat this procedure $100$ times.

If our burst clock model is well calibrated, the ground truth parameters should fall within the $p\%$ credible interval in $p\%$ of the simulation runs. In addition, the clock without bursts should mis-estimate ground truth parameters.

% Simulation configuration
In each of the $100$ simulation runs we simulate ultrametric phylogenetic trees with $20$ taxa according to a Yule model (a special case of the birth-death prior with no deaths) with strong priors on the height of $4$ internal nodes. These $4$ calibration points are necessary to infer the clock rate from the data. We use a relaxed clock model with a fixed standard deviation of $0.5$ and a lognormal prior with mean $0.35$ and $\sigma = 0.5$ on the clock rate.

At the same time, we simulate parameters for a burst clock model from an independent prior. In order to simplify the model selection between clocks with and without bursts, we implement a prior that selects the URC without bursts with a prior probability of $0.5$ as follows. The parameter $b$ is drawn from a normal distribution with mean $0$ and standard deviation $0.05$. Negative values for $b$ are treated as a plain non-burst clock model. (Positive values result in a burst clock model with $b$ as burst parameter.) In inference, $b$ is similarly permitted to take on negative values to represent a clock without bursts.

Based on the simulated tree and model parameters we further simulate data according to a continuous time Markov chain (CTMC) model with two states. We generated 5000 binary characters for each simulated language.
%Finally, we test how well the simulated parameters can be reconstructed from the data when using two distinct models: a burst clock model and a non-burst clock model. 

% Reconstruction configuration
For each set of simulated data, we sample parameters from the posterior distribution using BEAST's MCMC sampler. The posterior distribution is composed of the same priors and likelihood function used to generate the data.
The MCMC is run for $10^7$ steps with existing MCMC operators, storing a sample every $10^4$ steps. We discard the first $10\%$ of the samples as burn-in and compute the $95\%$ credible intervals on the remaining samples. Eventually, we evaluate in how many runs this credible interval covers the ground truth parameters. In a well calibrated model we expect that between $91$ and $99$ of the $100$ ground truth parameters are within the $95\%$ credible interval of the posterior samples.

\section{Case studies using empirical lexical data}
\label{s:lexical}

In order to assess whether the burst clock is a useful model for Bayesian
phylogenetics of languages, we use it to systematically revisit studies on Bayesian phylogenetics
on four well-studied language phylogenies:
Austronesian
\parencite{gray2009language,greenhill2017evolutionary,greenhill2018population},
Bantu
\parencite{grollemund2015bantu,greenhill2018population,currie2013cultural},
Indo-European
\parencite{bouckaert2012mapping,chang2015ancestryconstrained,gray2003language,holm2017steppe,rama2018three,willems2016using}
and
Sino-Tibetan \parencite{sagart2019dated,zhang2019phylogenetic}.
We expect that at least for some of these language families, the analysis will show
a preference of clocks with bursts over clocks without bursts,
in line with the results of \textcite{atkinson2008languages}.

We infer dated language phylogenies using a state-of-the-art inference model for each of these data sets, using a strict burst clock and a relaxed burst clock.
Both clock models are configured such that their priors produce a non-burst clock with a
probability of $\frac{1}{2}$ and a burst clock with a probability also of
$\frac{1}{2}$, allowing us to directly compare the burst and no-burst case and compute Bayes factors based on the posterior
distribution.
The model we use is the same for all four language families, as described below.
The formal model description, in the shape of an XML template file in the
style of literate programming \parencite{knuth1984literate}, can be found in the supplement,
which also contains the tools to add data and calibrations for each language
family to the template. 

\paragraph{Tree prior}
We assume a skyline fossilized birth/death tree prior.
% The only source on turnovers I can think of right now is the logfile by Sagart&al.
Due to colonization and Christian missionaries,
alphabetically written sources become available in many parts of the world around
1500 CE, and this means that the probability that a language is documented before
it goes extinct drastically increases around then. Old written sources are a
main source of temporal calibrations.
We therefore allow the sampling proportion to be different before and during the last 500 years.
For the other parameters of the tree prior (which describe the rates of language splits and extinctions) we make the simplified assumption that they are constant throughout the tree.


\paragraph{Substitution model}

While the binary covarion model has been shown to outperform the general binary CTMC
model on several occasions, its main purpose is to absorb varying transition
rates across (and along) branches. Substitutions are highly informative for our burst clock,
so we model substitutions using a general binary CTMC model.
This model has one parameter governing the ratio 
between the rate of transitions from “absent” to “present” (gain rate)
and the rate of transitions from “present” to “absent” (loss rate),
which are normalized such that a clock rate of $1$ means one expected
change (loss or gain) per time unit for each character.
We expect that the varying
rates of substitution along branches inform the branch lengths $l_i$
and the clock model parameters instead of having to be absorbed into covarion transitions.
Following \textcite{maurits2017beastling}, we assume that substitution rates are constant within a
meaning class, but that the substitution rates between different meaning classes
are distributed according to a Gamma distribution.

\paragraph{Clock model}
We test each data set with both a strict and a relaxed clock, in each case
comparing the results without bursts with the results
using a burst version of the clock. The prior on the number of changes per split for the 
burst clocks is estimated as follows. We aim for a broad prior centred around $b=0$,
where parameter values less than 0 are interpreted as probability mass in the point $b=0$ (i.\,e.\ no  bursts of evolution).
In the linguistics literature, we have found estimates of the amount of words a daughter language has not inherited from a particular ancestor, but instead innovated or borrowed from elsewhere. These loss rates are often
given in terms of the expected percentage of lexical
replacement in 1000 years. Early estimations
put this number roughly between 15\% and 20\%,
for loss rates between
$ r_{1 \rightarrow 0} = 1-(1 - 15\%)^{1/1000} = 1.63 × 10^{-4}$ and $2.23 × 10^{-4}$ \parencite{swadesh1955greater}.
A quantitative study by \textcite[p. 405]{pagel2000history} estimated $r_{1 \rightarrow 0} = 5.8 × 10^{-4}$.
From this loss rate we can derive a clock rate using the substitution model.
If 200 concepts are attested by a total of 5000 cognate sets and thus the frequency of presence is around 4\%, then $r_{1 \rightarrow 0} = 5.8 × 10^{-4}$
corresponds to a clock rate of very roughly $c = 2 \cdot 4\% \cdot 5.8 × 10^{-4}=4.64\times 10^{-5}$.
Assuming a time depth of the trees of generally up to 7000 years,
there are about $0.325$ changes in the tree for each cognate set. With about 500 languages or more for each of our 
families, there will be usually around 9 splits between the root and the
tips, which may contribute up to 30\% \parencite{atkinson2008languages} of the changes, so we take a
normal distribution for the burst parameter $b$ with $3\sigma = 0.30 \cdot 0.325 / 9$, so $\sigma=3.6 \times 10^{-3}$.
As a very rough estimate, this should provide a soft upper bound to the size of bursts.

\paragraph{Phylogenetic inference}
We infer the phylogenies using Markov chain Monte Carlo sampling, using the MCMC
software tool BEAST2 \parencite{drummond2015bayesian}. The time until convergence varies greatly
between the different data sets (with different numbers of languages, concepts, and
cognate sets each).
We run 5 replications of each of the chains, running them in bouts of 24 hours on a high-performance
computing cluster and sampling every 10'000th step, until each parameter has reached an effective sample size (ESS) of 
200 or more given a burnin of $10\%$.

The Python source code to generate the XML configuration files for BEAST2, as well as
the XML files themselves and the raw log file outputs of the BEAST runs are
available in the Supplementary Material.


\paragraph{Data}

The data for the phylogenetic analyses is composed of lexical items in comparable concepts (“word list” or “concept list”) annotated
for cognacy, i.\,e.\ presumed inheritance from a shared root.
We use the same binary root-meaning presence/absence coding also used in all
phylogenetic studies cited for these four language families.
We account for the ascertainment bias that the data
only includes cognate sets that are attested in any contemporary language.
We will discuss the sources of the lexical data for each of the language families in separate subsections below.

Dated trees with meaningful branch lengths and clock data also require calibration points.
We find three types of calibrations in the literature: Calibrations constraining the age of the most recent common ancestor (MRCA) of a group of languages to a particular range, calibrations describing a minimum age of a MRCA, and calibrations describing the age of non-contemporary tip language data.
The individual calibration points are specific to the language families and will also be discussed in the following subsections.



\subsection{Austronesian}\label{s:austronesian}
\input{supplement/austronesian/stats.tex}
The Austronesian language family is the second-largest language family of the world, found on many Pacific island groups of the pacific, in South East Asia, and on Madagascar.
Due to this wide spread, these languages have been regularly studied using phylogenetics, eg. by
\textcite{gray2009language,greenhill2017evolutionary,greenhill2018population}.
\paragraph{Lexical Data}
Among the articles using lexical data to infer Austronesian language phylogenies, only the second one
% gray2009language: “The data used in this study were extracted from the Austronesian Basic Vocabulary Database (“ABVD”) project (Greenhill et al. 2008). We selected the 400 languages/dialects with the most available data, and excluded known creoles and languages with large amounts of admixture (Table S1). We included two non-Austronesian languages as outgroups to “root” the trees: an archaic variant of the Sino-Tibetan language Chinese that was spoken between 2,300 and 2,900 years ago, and theTai-Kadai language Buyang. We extracted the cognate set data for these 400 languages across all 210 wordlist items. These data were translated into a binary matrix representing the presence or absence of each cognate set in each language.”
% greenhill20818population: “For the Austronesian languages we used the Austronesian Basic Vocabulary Database (ABVD, Greenhill et al., 2008) which contains wordlists for 210 semantic categories from 1,278 languages.”, not even mentioning data coding, no supplement
% greenhill2017evolutionary: “We used the ABVD (17) to find lexical data for the languages in the PIMdb. We identified 81 languages in both the PIMdb and the ABVD. [...] All lexical and cognate information is available online at https://abvd.shh.mpg.de/austronesian, and the cognate file is available in SI Materials and Methods and Data Set S4. are published with the acutal data in supplement.
\parencite{greenhill2018population} makes the associated lexical data available, instead of only describing the data gathering procedure.
Hovever, in that case the data set is reduced to the overlap with a data set on grammatical features.
All three papers use the Austronesian Basic Vocabulary Database for their lexical data, but the official version of that database
(\url{https://abvd.shh.mpg.de/austronesian/}) is published without a persistent identifier, not freely usable, and not available in a re-usable format, so we instead make use of the ABVD
data in the standardized CLDF format \parencite{cldf} curated on \url{https://github.com/lexibank/abvd}, which is published under a
permissive Creative Commons (CC-BY-4.0) license. We use the most recent version before the start of our study, commit \texttt{17a4b30922f9d1010667ae8974f814c624e3e9a4}
(2020-07-10). We filtered to the Austronesian doculects\footnote{The database contains several instances where different
sources for the same variety (judging by name and Glottocode) give rise to different ‘language’ objects in the data set, so the term
‘doculect’ appears more appropriate than ‘language’ or ‘dialect’ in discussing the composition of the data set, even though some languages may be aggregated from more than one source.} that have a coverage
of at least 85\% of all concepts (189 or more concepts). This results in \countlects{} doculects and \countconcepts{} concepts being included in the data.

\paragraph{Calibrations}
\newcommand{\abvd}[2]{#1 [\href{https://abvd.shh.mpg.de/austronesian/language.php?id=#2}{#2}]}
% gray2009language: clades not explicitly tied to calibrations, only description needing interpretation in Table S3
% greenhill2018population: No calibrations
% greenhill2017: To calibrate these clocks, we incorporated historical evidence of language divergence times as described by Gray et al. (50). We implemented five calibrations on the tree using normally distributed priors on the node heights. These calibrations were the following: (i) Proto-Oceanic (mean of 3,300 y, SD = 100 y), (ii) Proto-Central Pacific (mean of 3,000 y, SD = 100), (iii) Proto-Malayo-Polynesian (mean of 4,000 y, SD = 250), (iv) Proto-Micronesian (mean of 2,000 y, SD = 100), and (v) Proto-Austronesian (mean of 5,200 y, SD = 300).
Following \textcite{greenhill2017evolutionary}, we calibrate five nodes using normally
distributed priors. We supplement this with age constraints taken from \textcite[Table S3]{gray2009language}, where we interpret the ranges given as $\pm 2\sigma$ intervals of a normal distribution. This leads to the node calibrations given in \cref{t:austronesian}. We do not constrain the languages with these calibrations to be clades: a given calibrated MRCA node may be ancestral to more languages than explicitly listed.
\begin{table}
    \centering
    \begin{tabular}{lrrcp{5cm}}
\textbf{Languages} & \textbf{$\mu$} & \textbf{$\sigma$} & \textbf{Source} \\
all & 5,200 & 300 & \parencite{greenhill2017evolutionary} & i.\,e.\ on the root of our tree \\
\glot{Malayo-Polynesian}{mala1545} & 4,000 & 250 & \parencite{greenhill2017evolutionary} \\
\glot{Oceanic}{ocea1241} & 3,300 & 100 & \parencite{greenhill2017evolutionary} \\
\glot{Central Pacific}{cent2060} & 3,000 & 100 & \parencite{greenhill2017evolutionary} \\
\glot{Micronesian}{micr1243} & 2,000 & 100 & \parencite{greenhill2017evolutionary} \\
\glot{Malayo-Chamic}{nort3170} & 1,500 & 250 & \parencite{gray2009language} \\
\glot{Tuvalu and Tokelau}{elli1239} & 1,500 & 250 & \parencite{gray2009language} \\
\glot{East Polynesian}{east2449} & 1,475 & 167.5 & \parencite{gray2009language} \\
\glot{Malagasic}{mala1537} & 1,200 & 50 & \parencite{gray2009language} \\
\glot{Javanese}{java1253} & 1,200 & 50 & \parencite{gray2009language} \\
\glot{Chamic}{cham1330} & 1,150 & 175 & \parencite{gray2009language} \\
\abvd{Old Javanese}{290} & 950 & 125 & \parencite{gray2009language,zoetmulder1982old} & Tip calibration
    \end{tabular}
    \caption{Calibrations for Austronesian}
    \label{t:austronesian}
\end{table}

The only \glot{Reefs-Santa Cruz language}{reef1242} in our Austronesian lexical data set is \abvd{Äiwoo}{501}, so a calibration of the most recent ancestor of all Reefs-Santa Cruz languages is not possible.

In terms of tip calibrations given by \textcite{gray2009language}, the table row on \abvd{Old Javanese}{290} cites \textcite{zoetmulder1982old} for a date between 700 and 1200 BP.
For \abvd{Favorlang}{831}, some of the data derives from Dutch sources from the mid-1600s, others from wordlists collected around 1900. Such a mix of data makes it unsuitable for dating, so we completely exclude \abvd{Favorlang}{831} from the lexical data.
All their other tip calibrations do not apply to our filtered data set.

\subsection{Bantu}\label{s:bantu}
The Bantu languages are a part of the Atlantic-Congo language family. They
have been studied in lexical phylogenetics by
\textcite{grollemund2015bantu,greenhill2018population,currie2013cultural}.
\paragraph{Lexical Data}
% grollemund2015bantu: For each of the n=100 lexical items (meanings), we have used the comparative method wherever possible to identify cognate sets(words with the same meaning that derive from a common ancestor). Where it was not possible to establish strict correspondences for every word, we based our cognacy judgment on the principle of resemblance. This work was conducted by R.G. as part of her PhD and postdoctoral work on the Bantu languages (66). We identified 3,859 cognate sets across then=100 meanings.These were coded as binary characters for purposes of phylogenetic analysis. In practice, expert opinion on cognate classifications can differ (this difference also occurs in the alignment of gene sequence data where it is necessary to identify homologous genes), so we have conducted a series of analyses to check that our principal results are robust to variation in the data. We created subsampled data sets, with each one consisting of 50meanings randomly sampled without replacement from the data. These data sets were then converted to a binary matrix from which we inferred the tree. We repeated this procedure 100 times. We found that in 98% of these random samples based on just half the data, the tree we inferred showed the ladderized or pectinate backbone that we reported for the full-data set tree in Fig. 1. This result ensured that the signal for the tree we use to infer the Bantu migration route was robust to variation in the data
% greenhill2018population: “Basic vocabulary for 100 words from 409 Bantu languages were provided by Grollemund et al. (2015) in a phylogenetic data set that records a single variant per semantic category for each language.
% currie2013cultural: “Here, we use linguistic data from 542 spoken varieties of Bantu [16]. The names and alpha-numeric codes of all these languages are listed in the electronic Supplementary Material, table S1. Linguistic data in the form of different lexical items (‘words’) were taken from Bastin et al. [16]. These data code whether these basic vocabulary words from different languages can be considered cognate (i.e. they share a common origin). To facilitate phylogenetic analyses, these data were recoded into binary cognate sets reflecting the presence or the absence of each cognate in each language.
The supplementary data from the 2015 paper \parencite{grollemund2015bantu} is available from
\url{http://www.evolution.reading.ac.uk/DataSets.html}. A CLDF version of this data set by Robert Forkel, Tiago Tresoldi, Mark Pagel, and Rebecca Grollemund, published under the CC-BY-NC 4.0 license, can be found on \url{https://github.com/lexibank/grollemundbantu}. We use version v1.0rc6 of the data set.

\paragraph{Calibrations}
% greenhill2018population: No calibrations
% grollemund2015bantu: We used archaeological data to propose date ranges, and in one case a fixed date, for four nodes of our tree (labeled a–d in Fig. 1). The four calibrations are as follows: (a) 5,000 B.P. or older for Bantoid, non-Bantu (58); (b) 4,000–5,000 B.P. for Narrow Bantu (13, 14, 16, 44, 59, 60); (c) 3,000–3,500 B.P. for the Mbam-Bubi ancestor (61); and (d) 2,500 B.P. for Eastern Bantu (62). We used a uniform prior in our Bayesian tree inference for all calibration ranges.
We take the calibration ranges from \textcite{grollemund2015bantu}.
To obtain a proper prior where only lower bounds are given, we specify those as uniform priors with an upper bound of 20,000. Ranges we interpret as $\pm 2\sigma$ intervals of a normal distribution, like for Austronesian:
The dates appear to be rounded to a precision of 500 years, so it is dubious that eg. an age of 3499~yBP has 100\% prior probability for the Mbam-Bubi ancestor, while 3501~yBP has a prior probability of 0.
Again we do not enforce monophyly, which is particularly important for this language family, where two of the calibrated language groups (Bantoid and Mbam-Bubi) are paraphyletic in Glottolog. The calibrations can be seen in \cref{t:bantu}.
\begin{table}
    \centering
    \begin{tabular}{p{7cm}rrcl}
\textbf{Languages} & \textbf{min} & \textbf{max} & \textbf{Source}\\
non-Bantu Bantoid languages (aghemgrassfields, njengrassfields, mbulajarawan, bamungrassfields, fefegrassfields, okugrassfields, dugurijarawan, moghamograssfields, bwazzajarawan, komgrassfields, bilejarawan, kulungjarawan, mungakagrassfields, zaambojarawan, tivtivoid)& 5,000 & 20,000 & \parencite{grollemund2015bantu} & from lower bound\\
\textbf{Languages} & \textbf{$\mu$} & \textbf{$\sigma$} & \textbf{Source}\\
\glot{Narrow Bantu}{narr1281} & 4,500 & 250 & \parencite{grollemund2015bantu} \\
\glot{Mbam languages}{mbam1252} and \glot{Bubi}{bubi1250} & 3,250 & 125 & \parencite{grollemund2015bantu} \\
\glot{East Bantu}{east2731} & 2,500 & 50 & \parencite{grollemund2015bantu}
    \end{tabular}
    \caption{Calibrations for Bantu}
    \label{t:bantu}
\end{table}

\subsection{Indo-European}\label{s:indoeuropean}
Indo-European, the dominant language family of Europe, has been extensively studied using lexical Bayesian phylogenetics since the beginning
of the field
\parencite{bouckaert2012mapping,chang2015ancestryconstrained,gray2003language,holm2017steppe,rama2018three,willems2016using}

\paragraph{Lexical Data}
Data sets generally go back to Dyen's work \parencite{dyen1992indoeuropean,dyen1997comparative} in the 1990s and its derivatives such as IELex \parencite{ielex},
but have been improved
step by step. The most recent study correcting
the quality of cognate codes is by \textcite{chang2015ancestryconstrained}. Their different data sets are explicitly compared by \textcite{rama2018three}, who finds that the
‘\textsc{medium}’ data set fits the expected node ages best given a uniform tree prior. \Citeauthor{rama2018three} also argues qualitatively in favour of
that data set over the alternatives considered, so we base our analysis on that data set, available from
\url{https://github.com/PhyloStar/ie-phylo-exps/blob/a63c0b52f7772adc2341572932a74b23d92570df/medium1.nex}.

\paragraph{Calibrations}
Following the evidence presented by \textcite[Tables 7 and 12]{chang2015ancestryconstrained}, we implement the node and tip calibrations in \cref{t:indoeuropean}, which are minimum ages (capped at an upper bound of 20000~yBP using a uniform prior to obtain a proper prior distribution) or normal distributions as given by the reference. Because of the presence of several old languages, \cref{t:indoeuropean} lists all individual languages in each group to avoid confusion.
\begin{table}
  \centering
    \begin{tabular}{p{7cm}rrcl}
    \textbf{Languages} & \textbf{min} & \textbf{max} & \textbf{Source} \\
    Gothic, Old West Norse, Icelandic, Faroese, Norwegian, Swedish, Danish, Old English, English, Frisian, Old High German, German, Luxembourgish, Swiss German, Dutch, Flemish and Afrikaans & 2250 & 20000 & \parencite{chang2015ancestryconstrained} & Germanic  \\
    Latin, Nuorese, Cagliari, Romanian, Catalan, Portuguese, Spanish, French, Provencal, Walloon, Ladin, Romansh, Friulian and Italian & 1750 & 20000 & \parencite{chang2015ancestryconstrained} & Romance  \\
    Old West Norse, Icelandic, Faroese, Norwegian, Swedish and Danish & 1500 & 20000 & \parencite{chang2015ancestryconstrained} & Scandinavian  \\
    Czech, Slovak, Polish, Upper Sorbian, Ukrainian, Belarusian, Russian, Slovenian, Macedonian, Bulgarian, Serbian and Old Church Slavic & 1500 & 20000 & \parencite{chang2015ancestryconstrained} & Slavic  \\
    Lithuanian and Latvian & 1300 & 20000 & \parencite{chang2015ancestryconstrained} & East Baltic  \\
    Welsh, Breton and Cornish & 1250 & 20000 & \parencite{chang2015ancestryconstrained} & British Celtic  \\
    Irish and Scots Gaelic & 1050 & 20000 & \parencite{chang2015ancestryconstrained}  \\
    Tajik and Persian & 750 & 20000 & \parencite{chang2015ancestryconstrained}  \\
    \textbf{Languages} & \textbf{$\mu$} & \textbf{$\sigma$} & \textbf{Source} \\
    Hittite & 3400 & 100 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Vedic Sanskrit & 3250 & 250 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Avestan & 2500 & 50 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Ancient Greek & 2450 & 50 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Latin & 2150 & 50 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Gothic & 1650 & 25 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Classical Armenian & 1550 & 50 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Tocharian B & 1350 & 150 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Old Irish & 1200 & 100 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Old High German & 1150 & 50 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Old English & 1000 & 50 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Old Church Slavic & 1000 & 50 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Old West Norse & 800 & 50 & \parencite{chang2015ancestryconstrained} & Tip calibration \\
    Cornish & 300 & 100 & \parencite{chang2015ancestryconstrained} & Tip calibration
  \end{tabular}
  \caption{Calibrations for Indo-European}
  \label{t:indoeuropean}
\end{table}


\subsection{Sino-Tibetan}\label{s:sinotibetan}
The Sino-Tibetan language family, the fourth-largest family worldwide, has been recently studied using computational phylogenetic methods by two independent groups
\parencite{sagart2019dated,zhang2019phylogenetic}.
\paragraph{Lexical Data}
The lexical data is available as Supplementary Material for each of these two
articles. Both data sets are ultimately derived from the STEDT data set
\parencite{stedt}. \Citeauthor{sagart2019dated} are very explicit concerning their
data selection and cognate coding method and also make their BEAST2 file available from \url{https://github.com/lingpy/sino-tibetan-paper/blob/v1.0.3/BeastFiles/sinotibetan-beast-covarion-relaxed-fbd.xml}.
\Citeauthor{zhang2019phylogenetic} on the other hand retain a larger language sample.
While smaller, the \textcite{sagart2019dated} data set seems thus much more carefully
curated and re-usable, and is therefore preferable for our analysis.
The data underlying that article is curated on \url{https://github.com/lexibank/sagartst}, the specific analyses have been published on \url{https://github.com/lingpy/sino-tibetan-paper}.

\paragraph{Calibrations}
Our calibrations for Sino-Tibetan can be seen in \cref{t:sinotibetan}. They are derived as follows.
\Textcite{sagart2019dated} list a few fixed tip dates. Three of these tip dates are taken from the dating of earliest sources and rounded to the nearest century, so they actually come with an uncertainty of about $\sigma=25$. In their BEAST2 XML, these tip dates (even the Old Chinese tip date described with a uniform prior in the paper text, and which we take as a normal distribution in the same way as for Austronesian and Bantu) are assumed fixed.
\begin{table}
  \centering
    \begin{tabular}{p{7cm}rrcl}
    \textbf{Languages} & \textbf{$\mu$} & \textbf{$\sigma$} & \textbf{Source} \\
Beijing, Chaozhou, Guangzhou, Jieyang, Longgang, Xingning & 2100 & 50 & \parencite{sagart2019dated} & Sinitic dialects \\
     Old Chinese & 2550 & 125& \parencite{sagart2019dated} & Tip calibration \\
     Old Tibetan & 1200 & 25& \parencite{sagart2019dated} & Tip calibration \\
     Tangut & 900 & 25& \parencite{sagart2019dated} & Tip calibration \\
     Old Burmese & 800 & 25& \parencite{sagart2019dated} & Tip calibration \\
\end{tabular}
  \caption{Calibrations for Sino-Tibetan}
  \label{t:sinotibetan}
\end{table}

In addition, their BEAST2 XML file contains a uniform node calibration between 2000 and 2200 yBP for the MRCA of the Sinitic dialects (Beijing, Chaozhou, Guangzhou, Jieyang, Longgang, and Xingning). We like for the other language families, we replace the uniform range with a normal distribution for this MRCA calibration.
The additional node calibrations from \textcite{zhang2019phylogenetic} are either approximately given by the tip calibrations already (Chinese, Tibetan, Burmese), or not applicable to the reduced data set by \textcite{sagart2019dated} (Pumi, Yi).

% sagart2019dated: We specified calibrations as follows: Old Chinese, [2,800 to 2,300] yBP, in a uniform prior; Old Burmese, 800 yBP; Old Tibetan, 1,200 yBP; and Tangut, 900 yBP (the date range for Old Chinese corresponds to the period of the great Classical Chinese texts; the other dates correspond to the date of the earliest text rounded to the nearest century; see also SI Appendix, section 4).
% zhang2019: Supplementary table 2 (https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-019-1153-z/MediaObjects/41586_2019_1153_MOESM1_ESM.pdf):
% Chinese Normally distributed with mean 2700.0 and 150.0 standard deviation The earliest known written records of the Chinese language dates from about 1250 BC.
% Old Chinese Normally distributed with mean 2500.0 and 100.0 standard deviation. Tips Only.
% Tibetan dialects Normally distributed with mean 1150.0 and 50.0 standard deviation Tibetan dialects were formed in the mid-13th century. Tibetan dialects exclude the classical Tibetan.
% Burmese Truncated between 400.0 and 1200.0 The language is not attested until early in the 12th century, when it begins to appear on tone inscriptions in the temples of Pagan.
% Pumi Normally distributed with mean 750.0 and 50.0 standard deviation Pumi people migarated into the regions of Ninglang, Lijiang, Weixi and Lanpin from 13th century.
% Yi Normally distributed with mean 1500.0 and 100.0 standard deviation The expansion of Yi people to northeast and south Yunnan, and northwest Guizhou dated to 3th century. About in the eighth and ninth century, a kindom called Nazhao was ruled by Yi (Lolo) speakers but the people also included Bai language.

\section{Results}\label{s:results}

\subsection{Simulation study}

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{supplement/simulation_study/coverage.pdf}
    \caption{The simulated values (x-axes) and reconstructed $95\%$ credible intervals (y-axes) of the root height, clock rate and burst size ($b$) parameters. The parameters are simulated from the burst clock model, but we show a reconstruction without (left column) and with (right column) the burst clock. Red bars indicate runs where the credible interval of the reconstruction did not cover the actually simulated value.}
    \label{f:simulation}
\end{figure}

In the simulation study we simulated data with varying burst size $b$. The results show that the burst parameter $b$ is identifiable even for a relaxed clock, while inference of burst-clock data with a non-burst clock leads to systematic errors in important model parameters.

\Cref{f:simulation} shows the simulated and estimated root height, clock rate and burst size for reconstructions without bursts (left column; $b$ is fixed to $0$) and reconstructions with bursts (right column); For the reconstruction, the burst parameter $b$ was estimated, but it could be effectively set to $0$ both in the simulation and in the inference (represented using negative parameter values).
When bursts are simulated but the inference model permits no bursts, the model systematically mis-estimates the root height (top left in \cref{f:simulation}) or overestimates the clock rate (mid left in \cref{f:simulation}) to account for the extra evolution due to bursts.

Reconstructing the parameters with the burst clock model serves as a
verification that the MCMC can faithfully infer parameters under model
assumptions. We show that this is the case in the right column of \cref{f:simulation}. The $95\%$ coverage (numbers in the lower right corner) is between  $91$ to $99$ in for all parameters, as expected in a well calibrated model. For positive values, the model faithfully detected the burst size, even when it is very close to $0$.
For data simulated without bursts ($b\leq 0$), the inference faithfully recovers
a clock without bursts.

\subsection{Case studies}
\input{supplement/analysis/stats.tex}
\begin{figure}
  \centering
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{supplement/analysis/austronesian_years_per_split.png}
    \caption{Austronesian}
  \end{subfigure}
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{supplement/analysis/bantu_years_per_split.png}
    \caption{Bantu}
  \end{subfigure}
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{supplement/analysis/indoeuropean_years_per_split.png}
    \caption{Indoeuropean}
  \end{subfigure}
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{supplement/analysis/sinotibetan_years_per_split.png}
    \caption{Sino-Tibetan}
  \end{subfigure}
  \caption{Evolutionary contribution of each language split, in effective years}
  \label{f:peryear}
\end{figure}

In each burst clock run, the model was unconstrained and permitted to instead
select a model without bursts. The prior probability mass was equally distributed
between no bursts and bursts. This means that the Bayes factor can be directly estimated from the posterior sample.
Despite this uninformative prior, all samples of the
Austronesian, Bantu, and Indo-European analyses have a positive value for bursts,
so the Bayes factor in favour of the burst clock is the ESS of
the burst parameter in these models, which is between $\minessx$ for \minessn{} and
$\maxessx$ for \maxessn{}. For Sino-Tibetan,
the posterior probability of the burst clock is at least $\worstburst$ times as much as the clock
without bursts.

The average contribution of a language split varies between $\minx$ (5\%
quantile of \minn, including the posterior sample cases where language splits are not associated with no expected changes at all) and $\maxx$ (95\% quantile of \maxn)
expected changes per cognate class. Comparing this with the clock rate, we obtain
that around the time of a split, languages change about as much as otherwise in
about 100 to 150 years of independent evolution. The distributions of the
evolutionary contributions of split events compared to time of independent
evolution in shown in \cref{f:peryear}.

\begin{figure}
  \centering
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{supplement/analysis/austronesian_replacement.png}
    \caption{Austronesian}
  \end{subfigure}
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{supplement/analysis/bantu_replacement.png}
    \caption{Bantu}
  \end{subfigure}
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{supplement/analysis/indoeuropean_replacement.png}
    \caption{Indoeuropean}
  \end{subfigure}
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{supplement/analysis/sinotibetan_replacement.png}
    \caption{Sino-Tibetan}
  \end{subfigure}
  \caption{Expected lexical replacement in 1000~years for the different models
    in the different language families}\label{f:clock}
\end{figure}

The expected lexical replacement over 1000 years according to the different
inferences is shown in \cref{f:clock}. These values are derived from the loss
rate (transition rate from ‘presence’ to ‘absence’ of a cognate class in a
concept) which governs the clock rate of the inference. While the median of our
prior lies around 44\% lexical replacement over 1000 years, the data suggests
much slower replacement, closer to the \textcite{swadesh1955greater}
rule-of-thumb of 20\% over 1000 years, but varying widely around it, with
Austronesian showing much faster change and Sino-Tibetan much slower.

\paragraph{Convergence}
\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{supplement/analysis/runtimes.png}
  \caption{Runtimes of different analyses, in hours. Filled circles correspond to runs that reached an effective sample size of $\ess$ with $\burnin$ burnin for all parameters. Empty circles correspond to runs which had an ESS of less than $\ess$ for at least one model parameter, and which were thus considered unconverged and not included in the analysis.}\label{f:runtimes}
\end{figure}
We find a vastly different time to apparent convergence for the different
analyses, see \cref{f:runtimes}. While the strict clock for Sino-Tibetan converged within 50 hours,
several runs for Austronesian and Bantu with relaxed clock did not meet our
stopping criteria after more than 2500 hours.

Despite using the optimized relaxed clock
implementation by \textcite{orc}, the runs for Austronesian with relaxed clock
(with or without bursts) regularly jumped between two regions in the parameter
space, one containing trees with a mean height of ca. 4400 years and one with a
mean tree height above 5000 years. Following \textcite{brown2018behavior}, we cannot
assume that the posterior sample of these chains is informative about the
model's relative posterior probability for these two different parameter regions.
We can therefore not accurately describe the tree height and mean clock rate of
the relaxed Austronesian runs. All other parameters of these runs however appear
converged and uncorrelated with tree height, so they allow valid analysis.

All other runs have a large effective sample size for all parameters
and no apparent jumps between different parameter regions,
indicating convergence; some Bantu relaxed clock runs achieve
ESS of 200 for all parameters only for burnin values $\gg 10\%$.
We therefore included in our statistics above those runs where all parameters had an effective sample size of \ess after a burn-in of $\burnin$, instead of ESS 200 with a burn-in of $10\%$.


The complete analysis (data, tools to generate the BEAST XML files, generated XML files,
run log files including tree posterior samples, and analysis procedure) is
available in the Supplementary Material.

\section{Discussion}\label{s:discussion}

In this paper, we have introduced the burst clock, a generalization of existing clock models which includes punctuated evolution at splits in addition to gradual evolutionary change through time along a branch in the phylogenetic tree.

The burst clock associates every split (observed, or unobserved) in the tree with a constant amount of expected change $b$. These bursts of evolution are motivated by the observation of schismogenesis -- a process where linguistic differences between different social groups are exaggerated, thus accelerating the divergence between sister languages.

As our simulation study shows, phylogenetic inference is able to tease apart the
contribution of this faster evolution near phylogenetic splits from more general rate heterogeneity permitted under relaxed clock models.

Our phylogenetic analyses for well-studied language families show that the
burst clock is clearly the preferred model in all four language families we
studied. This holds irrespective of whether evolution across branches is assumed
to follow a strict or relaxed clock.
This indicates that the burst clock introduced in this paper has great potential for
the dated inference of language phylogenies.

Three
explanations have been suggested for the phenomenon that lineages with more
splits show more (lexical) disparity: deliberate/conscious schismogenesis,
founder effects \parencite{atkinson2008languages,greenhill2017evolutionary},
or a correlation of split rate with evolutionary divergence.
As a first step, it should be easy to investigate the question by
\textcite{gray2013three} whether schismogenesis affects more salient features
stronger by using different clocks with different burst values, but the same
underlying clocks, for phonetic, lexical, and structural features of languages.
If speakers' awareness plays a role in schismogenesis, we would expect with
\citeauthor{gray2013three} a higher amount of bursts for phonetics than for
lexicon, and for lexicon than for structural features, even when controlling for
the different rates of gradual change in these separate domains.

Another potential avenue of further investigation into the mechanisms
concerns the use of phylogeographic models \parencite{neureiter2021can}, where
migration rates can differ between different branches of the tree.
If schismogenesis is driven by an active process, its effects should be stronger
where the distance between related languages is smaller. This might be tested
using a variant of the burst clock where instead of branch clock rates $c$
burst amounts $b_i$ depend on the branch $i$ and comparing those bursts with
migration along each branch.

Independent of the precise mechanisms that lead to an acceleration of language divergence when languages split: the possibility of such effects has been conclusively shown before. With the package presented here it becomes finally possible to include it while inferring language family histories. This could have a major impact on dating: Tree heights might change drastically when switching from a clock without bursts to a clock with bursts, in particular where calibrations are shallow (cf. \cref{f:simulation}, see also Fig. S.1 in the Supplementary Material).

In this paper, we applied phylogenetic inference with burst clocks to subsets of the four largest language families of the world. The evolutionary dynamics of an expansive language family may differ greatly from the dynamics in smaller language families.
Phylogenetic studies for smaller language families do exist or are under way:
The field of linguistic phylogenetics is taking off rapidly at the moment.
As such, there is a great need to make phylogenetic studies in linguistics
extensible, replicable, and comparable. This need can also be seen in the context of
our present study.

Firstly, we observe that for
Austronesian and Bantu data, the relaxed clock mixes very badly, despite using
recent improvements to the implementation which were supposed to improve mixing
behaviour \parencite{orc}. In contrast with some of our other analyses, this does not improve when adding the burst clock, either. Given the reported success
of relaxed clocks in particular for Austronesian \parencite{gray2009language},
we consider it vital for the
field that phylogenetic articles give not only a high-level description of the
models used for inference, but also make their configuration files and outputs
available for inspection.
Only then can studies be replicated and convergence issues be noticed, and
new researchers can benefit from and build upon the existing templates that
have been used successfully.

Secondly, while Austronesian, Bantu, and
Indo-European have somewhat similar evolutionary dynamics in our analyses, Sino-Tibetan
seems to evolve noticeably differently. Without deeper analyses using comparable methodology, it would remain
unclear whether such observations stem from (potentially subtle)
differences in the models, or from different data coding
methods, or from particularities of the language family.

Thirdly, in quantitative diachronic typology, it is necessary to work with cross-family
data, so unified approaches using the same setup for different families, or even
hierarchical models connected by shared hyperpriors, have sometimes been
employed \parencite{dunn2011evolved,jager2021phylogenetic}. However, for lexical
data, individual language families are often studied by separate groups of
researchers with different model details and there is little indication that
models are re-used and compared between different language families; this article seems to be the first such study.

As a contribution to replicability and re-use of phylogenetic inference methods,
we have implemented our BEAST2 configuration
files as a template system using literate programming \parencite{knuth1984literate}. The BEAST2 configuration language is so
flexible as to allow us to structure the file as a readable model description,
while maintaining the functionality as a BEAST2 input file. We encourage other
researchers to adapt, criticize, and modify our inference procedure, so that 
the field can evolve towards comparable studies in
linguistic phylogenetics.

The effect we investigated in this paper
is not specific to linguistics. In fact, referring to parts
of an evolutionary history as “punctuated” goes back to the notion of
punctuated equilibria by \textcite{eldredge1972punctuated} in the 1970s, which
is the
assumption that biological evolution alternates between periods of “stasis” and
bursts of change.
In biology, the issue is not resolved. A recent observation by
\textcite{janzen2021nucleotide} indicates the need for a quantitative model of
punctuated evolution also for biological phylogenetics.
While
the past has mostly seen models developed for biological evolution being applied to
historical linguistics, 
it would be both feasible and meaningful to apply our burst clock to
phylogenetic inferences with biological data.
In addition to providing an immediate way to study biological evolution with punctuated equilibria, 
this would also contribute to the ongoing dialog about the similarities
and differences of cultural and biological evolutionary processes \parencite{list2016alignments,levinson2012tools}.

\paragraph{Acknowledgements}
We thank  Natalia Chousou-Polydouri, Peter Ranacher, Robert Weibel, Rik van Gijn, and Remco Bouckaert
for valuable discussions and feedback. We are very grateful in particular to Natalia Chousou-Polydouri and Peter Ranacher for extensive discussions concerning the methodology and the structure of the article.
We thank Robert Weibel, Paul Widmer and Balthasar Bickel for supervision and funding acquisition.
Funding supporting this work was provided by the
URPP “Language and Space”, University of Zurich; the NCCR “Evolving Language” with Swiss
NSF Agreement Nr. 51NF40\_180888; and the Swiss NSF Sinergia Project “Out of Asia”, Nr. CRSII5\_183578.

\paragraph{Author contributions}
GAK conceived of the idea, implemented the model and carried out the case studies. NN contributed to the idea, implementation and case study design, and implemented the simulation study. GAK and NN jointly interpreted the results and wrote and reviewed the manuscript.

%% In case CRediT is needed, it might be phrased as following:
% Conceptualization -- GAK (lead), NN
% Methodology -- GAK, NN, NCP (supporting)
% Software -- GAK, NN
% Validation -- NN
% Formal analysis -- GAK, NN
% Investigation -- GAK (lead), NN
% Resources -- PW, NN
% Data Curation -- GAK, NN
% Writing - Original Draft -- GAK, NN
% Writing - Review & Editing -- GAK, NN, NCP, PR, RW (supporting), RvG (supporting)
% Visualization -- NN (lead), GAK
% Supervision -- GAK, PR, RW
% Project administration -- GAK, RW
% Funding acquisition -- RW, PW, BB

\printbibliography{}

\end{document}

% Local Variables:
% TeX-engine: luatex
% TeX-command-extra-options: "-shell-escape"
% End:
